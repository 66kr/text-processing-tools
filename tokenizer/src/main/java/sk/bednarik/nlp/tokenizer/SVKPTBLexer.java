
/* The following code was generated by JFlex 1.7.0 */

package sk.bednarik.nlp.tokenizer;

// Stanford English Tokenizer -- a deterministic, fast, high-quality tokenizer.
// Copyright (c) 2002-2017 The Board of Trustees of
// The Leland Stanford Junior University. All Rights Reserved.
//
// This program is free software; you can redistribute it and/or
// modify it under the terms of the GNU General Public License
// as published by the Free Software Foundation; either version 2
// of the License, or (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU General Public License for more details.
//
// You should have received a copy of the GNU General Public License
// along with this program.  If not, see <http://www.gnu.org/licenses/>.
//
// For more information, bug reports, fixes, contact:
//    Christopher Manning
//    Dept of Computer Science, Gates 2A
//    Stanford CA 94305-9020
//    USA
//    java-nlp-support@lists.stanford.edu
//    http://nlp.stanford.edu/software/


import java.io.Reader;
import java.util.logging.Logger;
import java.util.Map;
import java.util.Properties;
import java.util.Set;
import java.util.regex.Pattern;

import edu.stanford.nlp.ling.CoreLabel;
import edu.stanford.nlp.ling.CoreAnnotations;
import edu.stanford.nlp.process.Americanize;
import edu.stanford.nlp.process.CoreLabelTokenFactory;
import edu.stanford.nlp.process.LexedTokenFactory;
import edu.stanford.nlp.process.AbstractTokenizer;
import edu.stanford.nlp.process.LexerUtils;
import edu.stanford.nlp.util.StringUtils;
import edu.stanford.nlp.util.logging.Redwood;


/** Provides a tokenizer or lexer that does a pretty good job at
 *  deterministically tokenizing English according to Penn Treebank conventions.
 *  The class is a scanner generated by
 *  <a href="http://www.jflex.de/">JFlex</a> from the specification file
 *  {@code SVKPTBLexer.flex}.  As well as copying what is in the Treebank,
 *  it now contains many extensions to deal with modern text and encoding
 *  issues, such as recognizing URLs and common Unicode characters, and a
 *  variety of options for doing or suppressing certain normalizations.
 *  Although they shouldn't really be there, it also interprets certain of the
 *  characters between U+0080 and U+009F as Windows CP1252 characters, since many
 *  LDC corpora actually mix CP1252 content into supposedly utf-8 text.
 *  <p>
 *  <i>Fine points:</i> Output normalized tokens should not contain spaces,
 *  providing the normalizeSpace option is true.  The space will be turned
 *  into a non-breaking space (U+00A0). Otherwise, they can appear in
 *  a couple of token classes (phone numbers, fractions).
 *  The original
 *  PTB tokenization (messy) standard also escapes certain other characters,
 *  such as * and /, and normalizes things like " to `` or ''.  By default,
 *  this tokenizer does most of these things.  However, you can turn them
 *  off by using the ptb3Escaping=false option, or, parts of it on or off,
 *  or unicode character alternatives on with different options. Or you can turn
 *  everything on for strict Penn Treebank 3 tokenization. You can also build an
 *  invertible tokenizer, with which you can still access the original
 *  character sequence and the non-token whitespace around it in a CoreLabel.
 *  And you can ask for newlines to be tokenized.
 *  <p>
 *  <i>Character entities:</i> For legacy reasons, this file will parse and interpret
 *  some simple SGML/XML/HTML tags and character entities.  For modern formats
 *  like XML, you are better off doing XML parsing, and then running the
 *  tokenizer on text elements.  But, we and others frequently work with simple
 *  SGML text corpora that are not XML (like LDC text collections).  In practice,
 *  they only include very simple markup and a few simple entities, and the
 *  minimal character entity
 *  support in this file is enough to handle them. So we leave this functionality
 *  in, even though it could conceivably mess with a correct XML file if the
 *  output of decoding had things that look like character entities.  In general,
 *  handled symbols are changed to ASCII/Unicode forms, but handled accented
 *  letters are just left as character entities in words.
 *  <p>
 *  <i>Character support:</i> SVKPTBLexer works for a broad range of common Unicode
 *  characters. It recognizes all characters that are classed as letter (alphabetic)
 *  or digit in Unicode.
 *  It also matches all defined characters in the Unicode range U+0000-U+07FF
 *  excluding most control characters except the ones very standardly found in
 *  plain text documents. Finally, a fair range of other characters, such as many
 *  symbols commonly found in English Unicode text and emoji are also recognized.
 *  <p>
 *  <i>Implementation note:</i> The scanner is caseless, but note, if adding
 *  or changing regexps, that caseless does not extend inside character
 *  classes.  From the manual: "The %caseless option does not change the
 *  matched text and does not effect character classes. So [a] still only
 *  matches the character a and not A, too."  Note that some character
 *  classes deliberately don't have both cases, so the scanner's
 *  operation isn't completely case-independent, though it mostly is.
 *  <p>
 *  <i>Implementation note:</i> This Java class is automatically generated
 *  from SVKPTBLexer.flex using jflex.  DO NOT EDIT THE JAVA SOURCE.  This file
 *  has now been updated for JFlex 1.6.1+.
 *
 *  @author Tim Grow
 *  @author Christopher Manning
 *  @author Jenny Finkel
 */


class SVKPTBLexer {

  /** This character denotes the end of file */
  public static final int YYEOF = -1;

  /** initial size of the lookahead buffer */
  private static final int ZZ_BUFFERSIZE = 16384;

  /** lexical states */
  public static final int YYINITIAL = 0;
  public static final int YyTokenizePerLine = 2;
  public static final int YyNotTokenizePerLine = 4;

  /**
   * ZZ_LEXSTATE[l] is the state in the DFA for the lexical state l
   * ZZ_LEXSTATE[l+1] is the state in the DFA for the lexical state l
   *                  at the beginning of a line
   * l is of the form l = 2*k, k a non negative integer
   */
  private static final int ZZ_LEXSTATE[] = { 
     0,  0,  1,  1,  2, 2
  };

  /** 
   * Translates characters to character classes
   */
  private static final String ZZ_CMAP_PACKED = 
    "\1\265\10\0\1\167\1\4\1\47\1\50\1\46\22\0\1\7\1\224"+
    "\1\12\1\37\1\136\1\174\1\15\1\11\1\212\1\213\1\216\1\126"+
    "\1\121\1\3\1\120\1\13\1\165\1\40\1\152\1\145\1\155\1\177"+
    "\4\164\1\123\1\25\1\1\1\10\1\14\1\2\1\175\1\56\1\106"+
    "\1\70\1\55\1\73\1\104\1\74\1\60\1\72\1\100\1\115\1\64"+
    "\1\54\1\61\1\71\1\62\1\67\1\66\1\57\1\63\1\65\1\75"+
    "\1\53\1\154\1\157\1\151\1\227\1\133\1\231\1\230\1\6\1\173"+
    "\1\20\1\105\1\35\1\17\1\42\1\103\1\43\1\23\1\41\1\77"+
    "\1\113\1\31\1\16\1\24\1\36\1\27\1\34\1\33\1\22\1\30"+
    "\1\32\1\44\1\5\1\153\1\156\1\150\1\225\1\172\1\264\1\226"+
    "\1\263\1\137\1\0\1\220\1\0\1\220\1\51\2\262\1\0\1\262"+
    "\7\0\1\163\1\221\2\220\1\262\2\26\2\262\6\0\1\132\1\260"+
    "\4\137\3\260\1\252\1\140\1\222\1\260\1\143\1\252\1\232\1\201"+
    "\1\260\2\130\1\162\1\206\3\260\1\130\1\140\1\222\3\135\1\260"+
    "\1\141\1\102\13\141\1\110\5\141\1\117\3\141\1\260\2\141\1\112"+
    "\4\141\2\206\1\101\13\206\1\107\5\206\1\116\3\206\1\260\2\206"+
    "\1\111\5\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206"+
    "\1\141\1\206\1\141\1\206\1\205\1\204\1\141\1\206\1\141\1\206"+
    "\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206"+
    "\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206"+
    "\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206"+
    "\1\147\1\146\1\141\1\206\1\141\1\206\1\141\1\206\1\140\1\141"+
    "\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141"+
    "\1\206\1\141\1\206\1\141\1\206\1\140\1\141\1\206\1\141\1\206"+
    "\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206"+
    "\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\203\1\202"+
    "\1\141\1\206\1\210\1\211\1\141\1\206\1\141\1\206\1\141\1\206"+
    "\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206"+
    "\1\141\1\206\2\141\1\206\1\141\1\206\1\141\1\206\1\21\1\206"+
    "\2\141\1\206\1\141\1\206\2\141\1\206\3\141\1\206\1\140\4\141"+
    "\1\206\2\141\1\206\3\141\2\206\1\140\2\141\1\206\2\141\1\206"+
    "\1\141\1\206\1\141\1\206\2\141\1\206\1\141\2\140\1\141\1\206"+
    "\2\141\1\206\3\141\1\206\1\141\1\206\2\141\1\206\2\140\1\141"+
    "\1\206\1\140\1\206\4\140\1\141\2\206\1\141\2\206\1\141\2\206"+
    "\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206"+
    "\1\141\1\206\1\141\1\206\1\141\2\206\1\141\1\206\1\141\1\206"+
    "\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206"+
    "\1\141\1\206\1\141\1\206\1\140\1\141\2\206\1\141\1\206\3\141"+
    "\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141"+
    "\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141"+
    "\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141"+
    "\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141"+
    "\1\140\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141"+
    "\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206\3\140"+
    "\3\140\2\141\1\206\2\141\2\206\1\141\1\206\4\141\1\206\1\141"+
    "\1\206\1\141\1\206\1\141\1\206\1\141\1\206\5\206\1\140\2\206"+
    "\1\140\1\206\1\140\2\206\3\140\2\206\1\140\1\206\1\140\2\206"+
    "\1\140\5\206\2\140\1\206\1\140\2\206\2\140\1\206\7\140\1\206"+
    "\2\140\1\206\2\140\1\206\3\140\6\206\5\140\1\206\12\140\2\206"+
    "\43\140\4\142\14\140\16\142\5\140\7\142\1\140\1\142\1\140\126\142"+
    "\1\207\52\142\1\141\1\206\1\141\1\206\1\140\1\142\1\141\1\206"+
    "\2\142\1\140\3\206\1\260\1\141\4\0\2\142\1\141\1\260\3\141"+
    "\1\0\1\141\1\0\2\141\1\140\21\141\1\0\11\141\4\206\1\140"+
    "\36\206\1\141\2\206\3\141\3\206\1\141\1\206\1\141\1\206\1\141"+
    "\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141"+
    "\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141\5\206\1\141"+
    "\1\206\1\142\1\141\1\206\2\141\1\206\1\140\3\141\60\141\60\206"+
    "\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206"+
    "\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206"+
    "\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206"+
    "\1\141\1\206\1\141\1\206\1\0\5\142\2\0\1\141\1\206\1\141"+
    "\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141"+
    "\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141"+
    "\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141"+
    "\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141"+
    "\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141"+
    "\1\206\2\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141"+
    "\1\206\1\141\1\206\1\141\1\206\1\206\1\141\1\206\1\141\1\206"+
    "\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206"+
    "\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206"+
    "\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206"+
    "\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206"+
    "\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206"+
    "\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206"+
    "\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206"+
    "\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206"+
    "\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206\1\141\1\206"+
    "\1\141\1\206\1\0\46\141\2\0\1\140\6\142\1\0\46\206\1\140"+
    "\1\0\1\260\1\214\6\0\37\142\16\161\1\260\1\161\1\260\2\161"+
    "\1\260\2\161\1\260\1\161\10\0\33\140\5\0\3\140\2\260\13\0"+
    "\4\260\2\0\5\260\1\137\1\260\3\0\4\160\1\160\6\161\1\260"+
    "\2\0\1\260\1\260\33\140\5\140\13\140\15\161\1\142\6\161\1\160"+
    "\12\76\1\260\2\125\1\260\2\140\1\161\143\140\1\260\1\140\7\161"+
    "\4\142\4\161\2\140\2\161\4\142\1\161\2\140\12\76\3\140\2\142"+
    "\1\140\3\260\13\260\1\0\1\142\1\140\1\161\36\140\20\161\15\142"+
    "\63\140\46\140\13\161\1\140\16\0\12\76\41\140\11\142\2\140\3\260"+